{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl (16.0 MB)\n",
      "   ---------------------------------------- 0.0/16.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 5.2/16.0 MB 31.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/16.0 MB 31.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/16.0 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/16.0 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.0/16.0 MB 18.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.24.12\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문서로드 (load documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지수 :6\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#PYMUPDFLoader객체 정의\n",
    "loader =  PyMuPDFLoader(\"data/snow-white.pdf\")\n",
    "\n",
    "#문서로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지수 :{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "백설공주\n",
      "옛날어느왕국에공주님이태어났어요.\n",
      "“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\n",
      "설공주라고불러야겠다.”\n",
      "왕과왕비는갓태어난딸을보며기뻐했어요.\n",
      "하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\n",
      "요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, 'page_content': '백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.\\n하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\\n요.\\n', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "#매타데이터\n",
    "print(docs[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문서분할(split documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수:6\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수:{len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 임베딩(embedding생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. db생성 (벡터스토어 생성 ) 및 저장\n",
    "* FAISS(facebook ai similarity seach)\n",
    "    * 페이스 북에서 개발한 유사도 검색 및 클러스터링 라이브러리\n",
    "    * 벡터 데이터셋에서 빠른 유사도 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왕자는깨어난백설공주를보고기뻐했어요.\n",
      "“공주님, 나는이웃나라왕자입니다.”\n",
      "“왕자님이나를다시살려주셨군요.”\n",
      "“나와결혼해주시겠어요?”\n",
      "“네, 좋아요!”\n",
      "두사람은일곱난쟁이와함께오래오래행복하게살\n",
      "았답니다.\n",
      "저녁이되자, 일곱난쟁이가돌아왔어요.\n",
      "난쟁이들은쓰러진백설공주를보고엉엉울었어요.\n",
      "백설공주는깊은잠에빠진것처럼보였지요.\n",
      "“백설공주님, 못된왕비의꾐에넘어갔군요.”\n",
      "“여전히아름다운우리공주님을캄캄한땅속에묻을순없어.”\n",
      "“오래오래볼수있게유리관에모시자.”\n",
      "어느날, 한왕자가숲을지나다가유리관을보았어요.\n",
      "“누구지? 이아름다운여인은?”\n",
      "“백설공주랍니다.”\n",
      "왕자는백설공주에게반해유리관을달라고부탁했어요.\n",
      "일곱난쟁이는백설공주를잘지킨다는약속을받고유리관을\n",
      "내주었지요.\n",
      "그런데신하들이유리관을옮기다돌부리에툭! 백설공주목\n",
      "에서사과조각이툭! \n",
      "“우아, 공주님이살아났어!”\n",
      "백설공주\n",
      "옛날어느왕국에공주님이태어났어요.\n",
      "“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\n",
      "설공주라고불러야겠다.”\n",
      "왕과왕비는갓태어난딸을보며기뻐했어요.\n",
      "하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\n",
      "요.\n",
      "왕은아름다운새왕비를맞았어요.\n",
      "그런데새왕비는자기보다아름다운사람을두고보\n",
      "지못했어요.\n",
      "왕비는진실만을말하는요술거울에게늘이렇게물\n",
      "었어요.\n",
      "“거울아, 거울아. 이세상에서누가가장아름답니?”\n",
      "“이세상에서가장아름다운사람은왕비님입니다.”\n",
      "그대답을들어야만차가운왕비얼굴에미소가번졌\n",
      "지요.\n",
      "시간이흘러백설공주는어여쁜소녀가되었어요.\n",
      "어느날, 왕비는요술거울에게물었지요.\n",
      "“거울아, 거울아. 이세상에서누가가장아름답니?”\n",
      "“왕비님도아름답지만백설공주가더아름답습니다.”\n",
      "화가난왕비는사냥꾼을불렀어요.\n",
      "왕비는사냥꾼에게백설공주를죽이라고명령했어요.\n",
      "하지만사냥꾼은차마그럴수없었어요.\n",
      "“가여운공주님, 왕비님이찾지못하도록멀리멀리떠\n",
      "나세요.”\n",
      "백설공주는울면서숲으로도망쳤어요.\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(\"왕자\"):\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 검색기(Retriver) 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터스토어에 있는 정보를 검색하고 생성\n",
    "retriver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.\\n하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\\n요.'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='저녁이되자, 일곱난쟁이가돌아왔어요.\\n난쟁이들은쓰러진백설공주를보고엉엉울었어요.\\n백설공주는깊은잠에빠진것처럼보였지요.\\n“백설공주님, 못된왕비의꾐에넘어갔군요.”\\n“여전히아름다운우리공주님을캄캄한땅속에묻을순없어.”\\n“오래오래볼수있게유리관에모시자.”\\n어느날, 한왕자가숲을지나다가유리관을보았어요.\\n“누구지? 이아름다운여인은?”\\n“백설공주랍니다.”\\n왕자는백설공주에게반해유리관을달라고부탁했어요.\\n일곱난쟁이는백설공주를잘지킨다는약속을받고유리관을\\n내주었지요.\\n그런데신하들이유리관을옮기다돌부리에툭! 백설공주목\\n에서사과조각이툭! \\n“우아, 공주님이살아났어!”'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 2, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='숲속을헤매던백설공주는외딴오두막에이르렀어요.\\n들여다보니오두막은비어있었어요.\\n“아무도없네. 좀쉬어가도될까? 어? 신기하다! 모든게작아. \\n어어? 이상하다! 모든게일곱. 의자도일곱, 접시도일곱. 어머, \\n침대도일곱개네.”\\n도망치느라치진백설공주는식탁위에있던빵을먹고나서\\n일곱번째침대에쓰러져잠들었어요.\\n밤이되자오두막주인인일곱난쟁이가돌아왔어요.\\n난쟁이들은집안이어질러진것을보고깜짝놀랐지요.\\n일곱째난쟁이가큰소리로외쳤어요.\\n“누가내침대에서자고있어!”\\n북적이는소리에잠이깬백설공주는왕비를피해도망쳤다고\\n이야기했어요.\\n“불쌍한공주님, 우리와함께살아요. 조심조심또조심. 낯선\\n사람에게는문을열어주지마세요.”\\n며칠이지나왕비는다시요술거울에게누가가장아름다운\\n지물었어요.\\n“왕비님도아름답지만백설공주님이천배는더아름답습니다.”\\n“사냥꾼이날속였구나. 내가직접해치우겠어!”'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 5, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='왕자는깨어난백설공주를보고기뻐했어요.\\n“공주님, 나는이웃나라왕자입니다.”\\n“왕자님이나를다시살려주셨군요.”\\n“나와결혼해주시겠어요?”\\n“네, 좋아요!”\\n두사람은일곱난쟁이와함께오래오래행복하게살\\n았답니다.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"백설공주와 일곱난쟁이는 어디서 만났어?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.프롬프트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당신은 질문-답변 작업을 위한 어시스턴트입니다\n",
    "주어진 문맥을 사용하여 질문에 답변하세요\n",
    "유치원선생님이 아이에게 말하는것처럼 매우 친절하고 부드러운 어조로 사용하세요\n",
    "따뜻하고 친근한 방식으로 말하세요\n",
    "답을 모르는 경우에는 모른다고 말씀하세요\n",
    "한국어로 답변하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "       \"\"\"You are an assistant for question-answering tasks. \n",
    "        Use the following pieces of retrieved context to answer the question.\n",
    "        Use a very kind and gentle tone like a kindergarten teacher talking to a child.\n",
    "        Speak in a warm and friendly way.\n",
    "        If you don't know the answer, just say that you don't know. \n",
    "        Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. llm 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm =  ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chain 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : retriver, \"question\" : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미안하지만, 잭과 콩나무에 대한 이야기는 여기에는 없어서 잘 모르겠어요. 다른 이야기를 물어봐 줄래요?\n"
     ]
    }
   ],
   "source": [
    "#체인 실행\n",
    " \n",
    "question = \"잭은 왜 콩나무를 타고 올라갔어??\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지수 :25\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "#PYMUPDFLoader객체 정의\n",
    "loader =  PyMuPDFLoader(\"data/10월호_산업동향.pdf\")\n",
    "\n",
    "#문서로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지수 :{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 10월호\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'data/10월호_산업동향.pdf', 'file_path': 'data/10월호_산업동향.pdf', 'page': 0, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, 'page_content': '2024년 10월호\\n', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수:86\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수:{len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임베딩\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "3\n",
      "호주 의회, 동의 없는 딥페이크 음란물 공유를 처벌하는 법안 통과\n",
      "n 호주 의회가 딥페이크 음란물을 동의 없이 공유한 경우 최대 징역 6년, 직접 제작하여 \n",
      "공유한 경우 최대 7년의 징역형을 부과하는 법안을 가결\n",
      "n 일부 의원은 딥페이크 음란물의 제작이 처벌 범위에 빠진 점을 지적하는 한편, 선거 관련 \n",
      "딥페이크에 대한 처벌 요구도 제기 \n",
      "KEY Contents\n",
      "£ 형법 개정안, 동의 없는 딥페이크 음란물 공유에 최대 7년의 징역형 부과\n",
      "n 호주 의회에서 2024년 8월 21일 딥페이크(Deepfake) 음란물을 동의 없이 공유한 경우, 최대 \n",
      "7년의 징역형을 부과하는 법안이 통과\n",
      "∙「형법 개정안(딥페이크 음란물) 2024」*는 AI나 기타 기술을 이용한 디지털 생성물 등 노골적인 \n",
      "콘텐츠를 동의 없이 공유한 경우 최대 6년, 이를 직접 제작하여 공유한 경우에는 최대 7년의 징역형을 부과\n",
      "범죄로 간주해야 한다고 주장\n",
      "∙래리사 워터스(Larissa Waters) 녹색당 상원 의원은 정부가 딥페이크 콘텐츠의 제작에 대한 처벌 \n",
      "규정을 법안에 포함하지 않은 점을 비판했으나, 정부는 이는 주와 준주*의 책임이라고 해명\n",
      "* 준주(Territory)는 주(State)와 비슷하지만 완전한 주의 지위나 권한을 갖지 않는 지역, 호주에는 6개의 주와 2개의 준주가 있음\n",
      "n 한편, 데이비드 포콕(David Pocock) 무소속 상원 의원은 딥페이크 처벌 범위가 선거와 관련된 영역까지 \n",
      "확대되어야 한다고 지적\n",
      "∙포콕 의원은 유권자를 오도하거나 속이기 위한 딥페이크가 전 세계적으로 폭발적으로 증가하고 있다며, \n",
      "동의 없이 사용되는 딥페이크는 민주주의를 위협하므로 선거 보호를 위해 금지되어야 한다고 강조\n",
      "2024년 10월호\n",
      "* The Criminal Code Amendment(Deepfake Sexual Material) Bill 2024\n",
      "∙마크 드레퓌스(Mark Dreyfus) 연방 법무부 장관은 “동의 없이 공유되는 딥페이크 음란물은 매우 \n",
      "심각한 형태의 학대이며, 여성·소녀 대상이 압도적으로 많고 유해한 성별 고정 관념을 지속시키며 젠더 \n",
      "기반 폭력을 강화”한다고 지적\n",
      "n 호주 연방 정부는 젠더 기반 폭력을 해결하려는 정책적 노력의 일환으로 2024년 6월 동 법안을 \n",
      "의회에 상정했으며, 이외에도 호주 국민 대상 개인정보 유출 행위를 불법화하는 별도의 법률 제정 \n",
      "계획을 수립\n",
      "£ 딥페이크 음란물 제작 및 선거 영역까지 처벌 범위를 확대해야 한다는 지적도 제기 \n",
      "n 동의 없는 딥페이크 음란물의 공유를 금지하는 이번 법안은 의회 전반의 폭넓은 지지를 받았으나, \n",
      "일각에서는 법안이 불충분하며 동의 없는 딥페이크 음란물의 제작 및 이를 제작하겠다는 위협도 \n",
      "범죄로 간주해야 한다고 주장\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(\"딥페이크\"):\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터스토어에 있는 정보를 검색하고 생성\n",
    "retriver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/10월호_산업동향.pdf', 'file_path': 'data/10월호_산업동향.pdf', 'page': 20, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='근로자의 41%는 일자리 시장이 나쁘다고 인식\\n∙일자리 시장이 나쁘다고 인식하는 미국 근로자의 58%는 AI 발전으로 일자리가 줄어들 것으로 \\n예상했으며, 일자리 시장이 좋다고 답변한 근로자 중에서는 일자리가 줄어들 것이라는 응답이 32%를 기록\\n∙전체 근로자 중에서는 48%가 AI 발전으로 일자리가 줄어들 것이라고 답했으며, AI 발전으로 \\n일자리가 늘어날 것이라는 응답은 11%, 영향이 없을 것이라는 응답은 28%를 기록\\nn 미국 근로자의 27%는 직장에서 AI 도구를 주 1회 이상 사용하며, 전혀 사용하지 않는 비율은 49%를 기록\\n∙2023년 7월에는 직장에서 AI 도구를 주 1회 이상 사용한다는 응답 비율이 20%였으며, 2024년 3월, \\n8월에는 해당 응답이 각각 25%, 27%로 증가\\nn 미국 근로자의 34%는 AI로 인한 실직이나 근무 시간 또는 급여가 줄어들 가능성을 우려하고 있으며, 이 \\n수치는 2023년 7월 이래 비슷한 수준을 유지'),\n",
       " Document(metadata={'source': 'data/10월호_산업동향.pdf', 'file_path': 'data/10월호_산업동향.pdf', 'page': 22, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='∙반면, 유통 분야는 2028년까지 24만 개의 일자리가 줄어들 수 있으며, 제조업과 금융 서비스 분야도 \\n각각 9만 개와 5만 개의 일자리가 감소 예상\\n∙AI와 같은 복잡한 기술의 구현과 유지 관리를 위해 40만 개의 기술 일자리가 생겨날 전망으로, \\n컴퓨터와 정보시스템 관리, 개발 및 데이터 엔지니어링 분야가 특히 유망\\nn AI는 새로운 일자리를 창출하는 동시에 일상 업무의 자동화를 통해 기존 근로자의 생산성을 개선할 \\n전망으로, AI는 영국 내 정규직 288만 명에 상당하는 작업을 수행 가능\\n∙시스템 관리자와 같은 기술 분야의 직원은 AI 활용으로 주당 최대 12.6시간을 절약하여 남는 시간을 \\n더욱 복잡한 작업에 투입 가능\\n£ 글로벌 인재 수요, 2028년까지 기술직을 중심으로 증가 전망\\nn 서비스나우는 영국 외 독일, 미국, 싱가포르, 인도, 일본, 캐나다, 호주의 인력 추이를 조사한 결과\\n를 바탕으로 2028년까지 글로벌 인재 수요가 공급을 계속해서 앞지를 것으로 예상'),\n",
       " Document(metadata={'source': 'data/10월호_산업동향.pdf', 'file_path': 'data/10월호_산업동향.pdf', 'page': 20, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='SPRi AI Brief |  \\n2024-10월호\\n18\\n유고브 조사 결과, 미국 근로자들 AI의 일자리 영향에 엇갈린 의견 표시\\nn 유고브의 조사 결과, 미국 근로자의 48%는 AI의 발전으로 일자리가 줄어들 것으로 \\n예상했으며, 34%는 AI로 인한 실직이나 근무 시간 또는 급여 감소를 우려\\nn 그러나 미국 근로자의 63%는 AI로 인한 실직이나 근무 시간 또는 급여 감소를 우려하지 \\n않았으며, 실제 AI로 인한 실직이나 근무 시간 또는 급여가 감소한 사례도 극소수 \\nKEY Contents\\n£ 미국 근로자의 48%는 AI로 인한 일자리 감소, 39%는 영향 없거나 일자리 증가 예상 \\nn 미국 여론조사기업 유고브(YouGov)가 2024년 8월 28일 발표한 설문조사 결과, 미국 근로자들은 \\nAI 기술 발전이 일자리에 미치는 영향에 대하여 엇갈린 의견을 표시\\n∙2024년 8월 8일~ 8월 10일 1,098명의 미국 성인을 대상으로 실시된 온라인 설문조사 결과, 미국'),\n",
       " Document(metadata={'source': 'data/10월호_산업동향.pdf', 'file_path': 'data/10월호_산업동향.pdf', 'page': 22, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='∙일본과 독일을 제외한 조사 국가들에서는 일자리가 증가할 전망으로, 미국에서는 2028년까지 100만 \\n개의 일자리가, 신흥 시장인 인도에서는 2028년까지 약 3,400만 개의 일자리가 추가될 전망\\n∙선진국에서 일자리 증가의 핵심 동인은 기술직으로, 영국, 미국, 캐나다에서는 전체 일자리 대비 \\n기술직이 훨씬 많이 늘어날 것이며 독일에서는 2028년까지 전체 일자리의 1.0% 감소에도 기술직은 \\n29%, 일본에서는 전체 일자리의 2.7% 감소에도 기술직은 43% 증가 예상\\n☞ 출처: Techradar, AI could boost UK job market by 610,000, 2024.09.06.\\n Servicenow, Impact AI: 2024 Workforce Skills Forecast, 2024.05.13.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"호주의 산업동향?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "       \"\"\"\n",
    "        You are an assistant in the question and answer task. \n",
    "        Use the following retrieved context fragments to answer the questions.\n",
    "        please be very detailed\n",
    "        Speak businesslikely\n",
    "        If you don't know the answer, just say you don't know. \n",
    "        Please answer in Korean.\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm =  ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : retriver, \"question\" : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주 의회는 딥페이크 음란물을 동의 없이 공유하는 행위를 처벌하는 법안을 통과시켰습니다. 이 법안에 따르면, AI나 기타 기술을 이용하여 생성된 디지털 콘텐츠를 동의 없이 공유할 경우 최대 6년의 징역형이 부과되며, 이를 직접 제작하여 공유한 경우에는 최대 7년의 징역형이 부과됩니다. \n",
      "\n",
      "일부 의원들은 딥페이크 콘텐츠의 제작에 대한 처벌 규정이 법안에 포함되지 않은 점을 비판하였으며, 이는 주와 준주의 책임이라는 정부의 해명이 있었습니다. 또한, 딥페이크의 처벌 범위를 선거와 관련된 영역까지 확대해야 한다는 의견도 제기되었습니다. 이는 유권자를 오도하거나 속이기 위한 딥페이크가 증가하고 있으며, 이러한 행위가 민주주의를 위협할 수 있기 때문입니다. \n",
      "\n",
      "따라서, 딥페이크 기술의 악용을 방지하기 위한 법적 조치가 강화되고 있는 상황입니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#체인 실행\n",
    " \n",
    "question = \"딥페이크정보에 대해 말해줘??\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
